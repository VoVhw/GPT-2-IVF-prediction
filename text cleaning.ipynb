{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TL4D7a1eIR8L","executionInfo":{"status":"ok","timestamp":1741394544014,"user_tz":300,"elapsed":16159,"user":{"displayName":"Hairong Wang","userId":"12167857472365731663"}},"outputId":"cf4c3c12-d9d5-4821-b2e4-488f326fc067"},"id":"TL4D7a1eIR8L","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"id":"68622ffa","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"68622ffa","executionInfo":{"status":"ok","timestamp":1741394715562,"user_tz":300,"elapsed":2234,"user":{"displayName":"Hairong Wang","userId":"12167857472365731663"}},"outputId":"42af0af6-3b72-4776-b59d-f27fe3b2c4d5"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","<ipython-input-7-f0609508ff91>:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df['CAUSE1'].replace(\"Blank\", pd.NA, inplace=True)\n","<ipython-input-7-f0609508ff91>:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df['CAUSE2'].replace(\"Blank\", pd.NA, inplace=True)\n","<ipython-input-7-f0609508ff91>:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df['CAUSE3'].replace(\"Blank\", pd.NA, inplace=True)\n"]}],"source":["import re\n","import string\n","import pandas as pd\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from wordcloud import WordCloud\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","import nltk\n","from nltk.corpus import stopwords\n","\n","# Download stopwords\n","nltk.download('stopwords')\n","stop_words = set(stopwords.words('english'))\n","\n","# Custom transformer for text cleaning\n","class TextCleaner(BaseEstimator, TransformerMixin):\n","    def __init__(self):\n","        pass\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X, y=None):\n","        def clean_text(text):\n","            text = text.lower()  # Lowercase text\n","            text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)  # Remove punctuation\n","            text = re.sub(r'\\d+', '', text)  # Remove digits\n","            text = ' '.join(word for word in text.split() if word not in stop_words)  # Remove stop words\n","            return text\n","\n","        return X.apply(clean_text)\n","\n","# Define the file path\n","file_path = '.../ed_data.csv'\n","\n","# Load the data into a pandas DataFrame\n","df = pd.read_csv(file_path)\n","\n","# Replace \"Blank\" with NaN in CAUSE1, CAUSE2, CAUSE3\n","df['CAUSE1'].replace(\"Blank\", pd.NA, inplace=True)\n","df['CAUSE2'].replace(\"Blank\", pd.NA, inplace=True)\n","df['CAUSE3'].replace(\"Blank\", pd.NA, inplace=True)\n","\n","# Merge RFV1-RFV5 into one variable\n","df['RFV'] = df[['RFV1', 'RFV2', 'RFV3', 'RFV4', 'RFV5']].apply(lambda x: ' '.join(x.dropna()), axis=1)\n","\n","# Merge CAUSE1-CAUSE3 into one variable\n","df['CAUSE'] = df[['CAUSE1', 'CAUSE2', 'CAUSE3']].apply(lambda x: ' '.join(x.dropna()), axis=1)\n","\n","# Drop the original RFV1-RFV5 and CAUSE1-CAUSE3 columns after cleaning\n","df.drop(columns=['RFV1', 'RFV2', 'RFV3', 'RFV4', 'RFV5', 'CAUSE1', 'CAUSE2', 'CAUSE3'], inplace=True)\n","\n","# Initialize the text cleaner\n","text_cleaner = TextCleaner()\n","\n","# Clean the 'RFV' and 'CAUSE' columns\n","df['RFV_clean'] = text_cleaner.transform(df['RFV'])\n","df['CAUSE_clean'] = text_cleaner.transform(df['CAUSE'])\n","\n","# Combine the cleaned 'RFV_clean' and 'CAUSE_clean' columns into one column\n","df['Combined_clean'] = df['RFV_clean'] + ' ' + df['CAUSE_clean']\n","\n","# Combine the text from the 'Combined_clean' column for word cloud and frequency analysis\n","combined_text = ' '.join(df['Combined_clean'].dropna())\n","\n","df.drop(columns=['RFV_clean', 'RFV_clean', 'RFV', 'CAUSE', 'CAUSE_clean'], inplace=True)\n","\n","# Generate word frequencies\n","word_freq = Counter(combined_text.split())\n","\n","# Filter words with frequency over 1500\n","filtered_word_freq = {word: freq for word, freq in word_freq.items() if freq > 800}\n","filtered_word_freq1 = {word: freq for word, freq in word_freq.items() if freq > 200}\n","\n","# Sort the filtered word frequencies by frequency\n","sorted_word_freq = dict(sorted(filtered_word_freq.items(), key=lambda item: item[1], reverse=True))\n","sorted_word_freq1 = dict(sorted(filtered_word_freq1.items(), key=lambda item: item[1], reverse=True))"]},{"cell_type":"code","execution_count":null,"id":"7ed344cc","metadata":{"id":"7ed344cc"},"outputs":[],"source":["output_file_path = '.../cleaned_ed_data.csv'\n","df.to_csv(output_file_path, index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}